---
title: "Oregon Campaign Response on Twitter"
author: "Hannah Metzler"
date: "3 Oct 2023"
output:
  pdf_document:
    df_print: kable
    keep_tex: yes
    toc_depth: 2
  word_document:
    toc_depth: '2'
  html_document:
    toc_depth: '2'
    df_print: paged
always_allow_html: yes
url_colour: blue
---

```{r setup, include=FALSE}
#what shall be printed in pdf output of this markdown? no code, no messages, no warnings
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)

# session settings
Sys.setlocale("LC_ALL", 'en_US.UTF-8')
options(scipen=10)

#packages
library(dplyr)
library(ggplot2) #for figures
library(scales)
library(cowplot) #for figures, placing next to each other
library(tidyr)
library(papaja) # print statistics in apa style
library(car)
library(lubridate)
```

```{r, data, include=FALSE}
# Run data pre processing the first time you use this script (takes about 1 minute or so)
#run it once with total = "all", and once with total = "suicide in the first line of code
# source("scripts/01preparedata202106.R")

#load the functions for making time series plots (plotTS) and for adding event lines to plots (events1819)
source('scripts/02_functions_figures_settings.R')
# or load data instead once data has been preprocessed

Sys.setlocale("LC_ALL", 'en_US.UTF-8') # to make sure weekdays are in English

#total number of tweets
df_all <- read.csv("data/TweetVolumeLong_TotalAll_202106.csv")

# tweets containing the term suicid*
df_sui <- read.csv("data/TweetVolumeLong_TotalSuicide_202106.csv") 

#define a function to format the dataframes
format = function(df){
  df = df %>% 
    mutate(date=as.Date(date), 
           state=factor(state),
           period = factor(period, levels = c("Baseline","2019 before campaign", "Campaign-week", "After", "More than 2 months after campaign"), ordered=TRUE), 
           weekday = factor(lubridate::wday(date, label=T, abbr=F)),#transform date to day of the week, first day: Tuesday
           weekday=factor(weekday, levels= c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"), ordered=TRUE))

#calculate the baseline: the year 2018 (see below for how we made decisions about how we calculate the baseline)
df <-df %>% 
  group_by(keywords, state) %>% 
  filter(date >= as.Date("2018-01-01") & date <= as.Date("2018-12-31")) %>% #define when baseline period ends
  summarise(bl=median(pr)) %>% 
  ungroup() %>% 
  #add the baseline to the df
  inner_join(df)
}

#format both dataframes:
df_all = format(df_all)
df_sui = format(df_sui)
```


```{r, suicide related vs all tweets, results=TRUE}
#choose data frame for figures and tables below: 
#choose total tweet volume: all tweets or tweets about suicide

total = "all" # "suicide" or "all"

if(total =="all"){
  df = df_all
print("Total number of tweets are all tweets per state")
} else if (total=="suicide") {
  df= df_sui
print("Total number of tweets are all tweets containing the word suicide(s) or suicidal per state")
}
```
# Keywords used to search tweets in the query for Crimson Hexagon

We used two different queries:

* Label "Breaking the silence": language:en AND region:USA.Or AND suicid* AND (breakingthesilenceor.com OR "#BreakingTheSilenceOR" OR "@BreakSilenceOR" OR "Breaking the silence" OR #Breakingthesilence) 
* Label "Lifeline": language:en AND region:USA.Or AND suicid* AND (800273talk OR 18002738255 OR "1-800-273-TALK" OR "1-800-273" OR "1-800-273-8255" OR Lifeline OR "suicide hotline" OR "suicide prevention hotline" OR Betheoneto OR #BeThe1To OR #Betheoneto OR Bethe1to) 
      - Bethe1to refers to "be the one to save a life", and was included because it is the  message promoted by the Lifeline during National Suicide Prevention Month and beyond. 

**Additional query settings**

* We only included tweets containing the word suicide or suicidal (AND suicid*) to make sure other campaigns with the terms "Breaking the silence" did not influence our results. (E.g. a campaign by Siemens focused on domestic violence.)
* We exclude tweets written by the campaign initiators themselves, to investigate only the response to their campaign. For this, we added "AND NOT (author:breakSilenceOr OR author:800273TALK OR author:Lines_for_Life)" to the query. 
* To download only English tweets from Oregon or Washington, we additionally used the query specifications: language:en AND region:USA.Or (or instead USA.WA). 
* Time period: January 2018 until October 2020

**Creating these queries was an iterative process:**

1. We first tested if including the word suicide in our query effected the number of Breaking the silence tweets, i.e. if there were many tweets that did not contain the word suicide which we would miss if we made "suicid*" a requirement. The effect was very small and neglible, therefore we always included the word suicide or suicidal. 
2. We tested if tweets containing hashtags that represent community actions, like #PreventSuicide #NotAlone #HelpThemConnect etc responded to the campaign. Including them did not include additional tweets that we did not already catch with the Breaking the silence and Lifeline keywords, indicating that these hashtags are mostly used in tweets that contain the Lifeline number.
3. We tested if excluding the initiators of the campaign as authors of tweet had any effect on the response, to make sure the response was not just due to their tweets. Excluding them did not influence the percentage of tweets much, we therefore exclude them to get a clean impact measure of the campaign, rather then measuring the campaign itself. 

\newpage

# Descriptive statistics

Number of days per time period in the dataset

```{r}
df_sui %>%
  #remove duplicate rows per date
  group_by(date) %>%
  filter(row_number()==1) %>%
  group_by(period) %>% 
  summarize(n = n())
```

## Total sample

Median and median absolute deviation of tweets per day across both states:

*Percent of all suicide related tweets*

```{r}
df_sui %>% 
  group_by(keywords, state) %>% 
  summarize(median_pr = median(pr), median_abs_dev = mad(pr))
```

*Percent of all tweets*

```{r}
df_all %>% 
  group_by(keywords, state) %>% 
  summarize(median_pr = median(pr), median_abs_dev = mad(pr))
```



## Total number of tweets and median number of tweets per day in each state

*All suicide related tweets*

```{r}
tots <- df_sui %>% 
  group_by(state) %>%
  filter(keywords=="Breaking the silence") %>% #choose only one of the repeated datasets (tot long the same every time)
  summarize(totaltweets = round(sum(as.numeric(tot_n)), 2),
            tweetsperday = round(median(as.numeric(tot_n)), 2)) %>% 
  ungroup()
tots
```

*All tweets*

```{r}
tota <- df_all %>% 
  group_by(state) %>%
  filter(keywords=="Breaking the silence") %>% #choose only one of the repeated datasets (tot long the same every time)
  summarize(milliontweets = round(sum(as.numeric(tot_n)/1000000), 2),
            tweetsperday = round(median(as.numeric(tot_n)), 2)) %>% 
  ungroup()
tota
```

*How many tweets contain the word suicide or suicidal, in percent of all tweets?*

```{r}
join_all = df_all %>% 
  group_by(date, state) %>% 
  slice(1) %>% 
  ungroup() %>%
  select(date, state, tot_n, pr)
join_sui = df_sui %>% 
  group_by(date, state) %>% 
  slice(1) %>% 
  ungroup() %>% 
  select(date, state, tot_n, pr)
df_both = inner_join(join_all, join_sui, by=c("date", "state"), suffix=c(".all", ".sui"))

pr_sui = df_both %>% 
  mutate(pr_suicide = 100/tot_n.all*tot_n.sui) %>% 
  group_by(state) %>% 
  summarise(mean_pr = round(mean(pr_suicide), 3))
pr_sui
```

## Number of tweets per query per time period 

* Baseline: the year 2018
* Campaign-week: 7-14 April 2019
* After: 15 April until 14 June 2019 (2 months after the campaign)

*Percent of all suicide related tweets*

```{r}
medianperiod = as.data.frame(df_sui %>% 
  group_by(state, keywords, period) %>%
  summarize(mediann = round(median(as.numeric(keywords_n)), 2),
            madn=round(mad(keywords_n), 2), 
            maxn = max(keywords_n),
            medianpr =round(median(as.numeric(pr)), 3), 
            madpr=round(mad(pr), 3),
            maxpr = round(max(pr),3))%>% 
  ungroup())
filter(medianperiod, state=="Oregon")
filter(medianperiod, state=="Washington")
write.csv(medianperiod, './output/median_per_period_totalSuicid*.csv', row.names=F)
```


*Percent of all tweets*

```{r}
statsperiod = as.data.frame(df_all %>% 
  group_by(state, keywords, period) %>%
  summarize(mediann = round(median(as.numeric(keywords_n)), 2),
            madn=round(mad(keywords_n), 2), 
            maxn = max(keywords_n),
            medianpr =round(median(as.numeric(pr)), 3), 
            madpr=round(mad(pr), 3),
            maxpr = round(max(pr),3))%>% 
  ungroup())
filter(statsperiod, state=="Oregon")
filter(statsperiod, state=="Washington")
write.csv(statsperiod, './output/median_per_period_TotalAll.csv', row.names=F)
```

## Descriptive statistics summary

We analysed a total number of `r filter(tota, state=="Oregon")$milliontweets` million tweets from Oregon, and `r filter(tota, state=="Washington")$milliontweets` million tweets from Washinton. `r filter(tots, state=="Oregon")$totaltweets` and `r filter(tots, state=="Washington")$totaltweets` of these tweets were related to suicide, respectively, corresponding to `r pr_sui$mean_pr[1]` and `r pr_sui$mean_pr[2]`%.  During the period analysed from January 1 2018 until November 30 2019, there were very few tweets that mention mention the terms “Break the Silence” outside of the campaign window, resulting in a median of 0%. For instance, there are only 9 tweets across both states in the entire baseline year.  However, around `r round(median(filter(df_all, keywords=='Lifeline')$pr), 3)`% of all tweets refer either to the Lifeline or to BeTheOneToo in both Oregon and Washington on average. 

\newpage

# Statistical test to compare tweet numbers per time period between states


## Using the original time periods defined in the paper

```{r}
#calculate sum of tweets per period for total and query tweets
n_tweets_per_period = as.data.frame(
  df_sui %>%
    #remove the time period after the campaign
    filter(period !="More than 2 months after campaign") %>% 
    #count tweets per category
    group_by(state, period, keywords) %>%
    summarize(keywords_n = sum(keywords_n),
            total_n = sum(tot_n))%>% 
    ungroup()) %>% 
  pivot_wider(names_from = state, 
              values_from = c(keywords_n, total_n)) %>% 
  rename("query_Or" = keywords_n_Oregon, "query_Wa" = keywords_n_Washington, "total_Or"= total_n_Oregon, "total_Wa" = total_n_Washington) %>% 
    mutate(keywords =  dplyr::recode(keywords, "Breaking the silence" = "Campaign"))

example = filter(n_tweets_per_period, period =="2019 before campaign" & keywords == "Breaking the silence")
```

*Sum of tweets (absolute numbers) per time period and state, for tweets containing query terms and total volume of suicide-related tweets*

These tweet volumes are used to estimate the proportion of tweets with query terms out of all suicide-related tweets, to then calculate a two-sample proportions Chi-square test. 

```{r}
n_tweets_per_period %>% 
  arrange(keywords) %>% 
  select(keywords, period, query_Or, total_Or, query_Wa, total_Wa)
```

*Issues* 

* Sample size of tweets per time period varies a lot between time periods, and is generally very high for all periods but the campaign week. 
* With high sample sizes, even small differences get significant. 
* In Oregon, there is some activity using campaign keywords already before the campaign, this leads to a significant difference between states before the campaign already. 

```{r}
# Proportions test: compare n tweets with query terms against total tweets
# prop.test(x = c(query_terms_Oregon, query_terms_Washington), n = c(total_tweets_Oregon, total_tweets_Washington), alternative = "two.sided")
#running multiple tests at once: https://cameronpatrick.com/post/2023/06/dplyr-fitting-multiple-models-at-once/
OvsW = n_tweets_per_period %>% 
  group_by(keywords, period) %>% 
  summarize(
    proptest = list(
      prop.test(x = c(query_Or, query_Wa), n = c(total_Or, total_Wa), alternative = "two.sided", correct = FALSE) 
      #continuity correction false because it only matters for small sample sizes. For our sizes, result is the same with and without
      )
  ) %>% 
  ungroup()

OvsW$keywords =   dplyr::recode(OvsW$keywords, "Breaking the silence" = "Campaign")

# #look at one test in the list: 
# OvsW$proptest[[1]]
# # structure of the list: 
# str(OvsW$proptest)

#put important estimates into a table
OvsW$pr_diff= round(sapply(OvsW$proptest, function(x) x$estimate[1])-(sapply(OvsW$proptest, function(x) x$estimate[2])), 3)*100
OvsW$pr_Or= round(sapply(OvsW$proptest, function(x) x$estimate[1]),4)*100
OvsW$pr_Wa= round(sapply(OvsW$proptest, function(x) x$estimate[2]),4)*100
OvsW$Chisquared = round(sapply(OvsW$proptest, function(x) x$statistic), 2)
OvsW$df = sapply(OvsW$proptest, function(x) x$parameter)
OvsW$p.value = round(sapply(OvsW$proptest, function(x) x$p.value), 3)
OvsW$ci_lower = round(sapply(OvsW$proptest, function(x) x$conf.int[1]), 4)*100
OvsW$ci_upper = round(sapply(OvsW$proptest, function(x) x$conf.int[2]), 4)*100

pre_Breaking = filter(OvsW, period =="2019 before campaign" & keywords == "Campaign")
```

* Example Breaking the silence query in 2019 before the campaign:

  * In Oregon, 149 tweets contained query terms, out of a total of 72873 suicide-related tweets. Percent: `r example$query_Or/example$total_Or*100`.
  * In Washington, 6 tweets contained query terms, out of a total of 92167 suicide-related tweets. Percent: `r example$query_Wa/example$total_Wa*100`.
  * These 2 proportions are significantly different: $\chi^2$ = `r pre_Breaking$Chisquared`(`r pre_Breaking$df`), p = `r round(pre_Breaking$p.value, 3)`

*Proportion tests between states per time period and query*:

* In the time before the campaign, there is a significant difference for the campaign keywords, although only of 0.3 percent. 
  * This could be due to campaign tweets already being published in the week before the campaign (from March 30 2019 onward). See the analysis for each week 4 sections further down. Was April 7 really the start of the campaign?
* For lifeline keywords, the difference is only in the campaign week - probably this is just less noisy data, because there are way more tweets with lifeline related terms. 


```{r}
select(OvsW, -c(proptest))
```
Percent difference: Oregon minus Washington. (If positive, the proportion in Oregon was higher.)

### Length of the different time periods - maybe normalize?

Count of days per period: There are large differences, and they are even larger for tweet numbers instead of days. 

```{r}
df_sui %>%
  #remove days after November 30 2019
  filter(date < as.Date("2019-11-30")) %>% 
  #remove duplicate rows per date
  group_by(date) %>%
  filter(row_number()==1) %>%
  group_by(period) %>% 
  summarize(n = n())
```

## Using 8 day periods just before and after the campaign, to normalize the length of periods

* 8 days before the campaign, 8 days campaign, 8 days after the campaign. 
* Issue here: In the 8 days before, there is already quite some campaign activity in Oregon. So the difference in the pre-period is again significant. 

Print the first date of each of these periods: 

```{r}
# Define equal time periods for statistical tests
df_sui = df_sui %>% 
   mutate(period8days = as.factor(case_when(
    date >= as.Date("2019-04-07")-8  & date < as.Date("2019-04-07") ~ "8 days before",
    date >= "2019-04-07" & date <= "2019-04-14" ~  "8 campaign days",
    date >= as.Date("2019-04-15")  & date < as.Date("2019-04-15")+8  ~ "8 days after",
    TRUE ~ "All other time periods"))) %>% 
    mutate(period8days = factor(period8days, levels = c("8 days before", "8 campaign days", "8 days after","All other time periods"), ordered=TRUE))

df_sui %>% 
  group_by(period8days) %>% 
  slice(1) %>% 
  select(keywords, state, date, period8days) 
```


```{r}
#calculate sum of tweets per period for total and query tweets
n_tweets_per_period = as.data.frame(
  df_sui %>%
    #remove the time period after the campaign
    filter(period !="More than 2 months after campaign") %>% 
    #remove time periods not within the 8 day windows
    filter(period8days !="All other time periods") %>% 
    #count tweets per category
    group_by(state, period8days, keywords) %>%
    summarize(keywords_n = sum(keywords_n),
            total_n = sum(tot_n))%>% 
    ungroup()) %>% 
  pivot_wider(names_from = state, 
              values_from = c(keywords_n, total_n)) %>% 
  rename("query_Or" = keywords_n_Oregon, "query_Wa" = keywords_n_Washington, "total_Or"= total_n_Oregon, "total_Wa" = total_n_Washington) %>%
  mutate(keywords =  dplyr::recode(keywords, "Breaking the silence" = "Campaign"))

example = filter(n_tweets_per_period, period8days =="8 days before" & keywords == "8 campaign days")
```

*Sum of tweets (absolute numbers) per time period and state, for tweets containing query terms and total volume of suicide-related tweets*

```{r}
n_tweets_per_period %>% 
  arrange(keywords) %>% 
  select(keywords, period8days, query_Or, total_Or, query_Wa, total_Wa)
```

```{r}
# Proportions test: compare n tweets with query terms against total tweets
OvsW = n_tweets_per_period %>% 
  group_by(keywords, period8days) %>% 
  summarize(
    proptest = list(
      prop.test(x = c(query_Or, query_Wa), n = c(total_Or, total_Wa), alternative = "two.sided", correct = TRUE) 
      )
  ) %>% 
  ungroup()
OvsW$keywords =   dplyr::recode(OvsW$keywords, "Breaking the silence" = "Campaign")

#put important estimates into a table
OvsW$pr_diff= round(sapply(OvsW$proptest, function(x) x$estimate[1])-(sapply(OvsW$proptest, function(x) x$estimate[2])), 3)*100
OvsW$pr_Or= round(sapply(OvsW$proptest, function(x) x$estimate[1]),4)*100
OvsW$pr_Wa= round(sapply(OvsW$proptest, function(x) x$estimate[2]),4)*100
OvsW$Chisquared = round(sapply(OvsW$proptest, function(x) x$statistic), 2)
OvsW$df = sapply(OvsW$proptest, function(x) x$parameter)
OvsW$p.value = round(sapply(OvsW$proptest, function(x) x$p.value), 3)
OvsW$ci_lower = round(sapply(OvsW$proptest, function(x) x$conf.int[1]), 4)*100
OvsW$ci_upper = round(sapply(OvsW$proptest, function(x) x$conf.int[2]), 4)*100

pre_Breaking = filter(OvsW, period8days =="8 days before" & keywords == "8 campaign days")
```

*Proportion tests between states per time period of 8 days and query*:



```{r}
select(OvsW, -c(proptest))
```
Percent difference: Oregon minus Washington. (If positive, the proportion in Oregon was higher.)


## Using 8 day periods one month before (March) and one month after the campaign (May)

* All periods are 8 days long, from 7-14th of each month, with April being the campaign month, March before the campaign, and May after the campaign. 
* Now, there are 0 campaign tweets in the month before the campaign, so we cannot calculate a test. But at least it is a clean result. 

Print the first date of each of these periods: 

```{r}
# Define equal time periods for statistical tests
df_sui = df_sui %>% 
   mutate(period8days = as.factor(case_when(
    date >= as.Date("2019-03-07")  & date <= as.Date("2019-03-14") ~ "1 month before",
    date >= "2019-04-07" & date <= "2019-04-14" ~  "8 campaign days",
    date >= as.Date("2019-05-07")  & date <= as.Date("2019-05-14")  ~ "1 month after",
    TRUE ~ "All other time periods"))) %>% 
    mutate(period8days = factor(period8days, levels = c("1 month before", "8 campaign days", "1 month after","All other time periods"), ordered=TRUE))

df_sui %>% 
  group_by(period8days) %>% 
  slice(1) %>% 
  select(keywords, state, date, period8days) 
```


```{r}
#calculate sum of tweets per period for total and query tweets
n_tweets_per_period = as.data.frame(
  df_sui %>%
    #remove the time period after the campaign
    filter(period !="More than 2 months after campaign") %>% 
    #remove time periods not within the 8 day windows
    filter(period8days !="All other time periods") %>% 
    #count tweets per category
    group_by(state, period8days, keywords) %>%
    summarize(keywords_n = sum(keywords_n),
            total_n = sum(tot_n))%>% 
    ungroup()) %>% 
  pivot_wider(names_from = state, 
              values_from = c(keywords_n, total_n)) %>% 
  rename("query_Or" = keywords_n_Oregon, "query_Wa" = keywords_n_Washington, "total_Or"= total_n_Oregon, "total_Wa" = total_n_Washington) %>%
  mutate(keywords =  dplyr::recode(keywords, "Breaking the silence" = "Campaign"))

example = filter(n_tweets_per_period, period8days =="1 month before" & keywords == "8 campaign days")
```

*Sum of tweets (absolute numbers) per time period and state, for tweets containing query terms and total volume of suicide-related tweets*

Each of these periods is 8 days long. 

```{r}
n_tweets_per_period %>% 
  arrange(keywords) %>% 
  select(keywords, period8days, query_Or, total_Or, query_Wa, total_Wa)
```

```{r}
# Proportions test: compare n tweets with query terms against total tweets
OvsW = n_tweets_per_period %>% 
  group_by(keywords, period8days) %>% 
  summarize(
    proptest = list(
      prop.test(x = c(query_Or, query_Wa), n = c(total_Or, total_Wa), alternative = "two.sided", correct = TRUE) 
      )
  ) %>% 
  ungroup()
OvsW$keywords =   dplyr::recode(OvsW$keywords, "Breaking the silence" = "Campaign")

#put important estimates into a table
OvsW$pr_diff= round(sapply(OvsW$proptest, function(x) x$estimate[1])-(sapply(OvsW$proptest, function(x) x$estimate[2])), 3)*100
OvsW$pr_Or= round(sapply(OvsW$proptest, function(x) x$estimate[1]),4)*100
OvsW$pr_Wa= round(sapply(OvsW$proptest, function(x) x$estimate[2]),4)*100
OvsW$Chisquared = round(sapply(OvsW$proptest, function(x) x$statistic), 2)
OvsW$df = sapply(OvsW$proptest, function(x) x$parameter)
OvsW$p.value = round(sapply(OvsW$proptest, function(x) x$p.value), 3)
OvsW$ci_lower = round(sapply(OvsW$proptest, function(x) x$conf.int[1]), 4)*100
OvsW$ci_upper = round(sapply(OvsW$proptest, function(x) x$conf.int[2]), 4)*100

pre_Breaking = filter(OvsW, period8days =="1 month before" & keywords == "8 campaign days")
```

*Proportion tests between states per time period of 8 days and query*:

```{r}
select(OvsW, -c(proptest))
```
Percent difference: Oregon minus Washington. (If positive, the proportion in Oregon was higher.)

## Proportion test for each week in the year 2019

The campaign started and ended on a Sunday, these are 8 days. The 8th day of the campaign week, is assigned to the campaign week itself. All weeks with zero campaign or lifeline related tweets are not shown in the results table (we cannot do a test to compare 2 proportions = 0).

Assigning numbers to weeks: 

```{r}
# do the same per week?
df_sui_weeks = as.data.frame(df_sui %>%
                arrange(keywords, date) %>%
                mutate(week = lubridate::epiweek(date)))
df_sui_weeks$keywords =  dplyr::recode(df_sui_weeks$keywords, "Breaking the silence" = "Campaign")

df_sui_weeks %>%
  select(keywords, period, date, weekday, week) %>%
  group_by(date) %>%
  filter(row_number()==1) %>%
  ungroup() %>%
  #campaign week
  filter(date > as.Date('2019-04-05') & date <as.Date("2019-04-16"))

#assign the sunday at end of the campaign (day 8) to week 15
df_sui_weeks[df_sui_weeks$date == "2019-04-14", ]$week = rep(15, 4)
```

Show the first date of every week: 

```{r}
weekstart = df_sui_weeks %>%
  filter(period != "Baseline") %>% 
  select(period, date, weekday, week) %>%
  group_by(week) %>%
  slice(1) %>%
  ungroup()
weekstart[1:25, ]
```



```{r}
#calculate proportion per week
n_tweets_week = df_sui_weeks %>%
  #exclude baseline year
  filter(!period %in% c("Baseline")) %>% 
  group_by(state, keywords, week) %>%
  summarize(keywords_n = sum(keywords_n),
            total_n = sum(tot_n))%>%
  ungroup() %>%
  pivot_wider(names_from = state,
              values_from = c(keywords_n, total_n))%>% 
  rename("query_Or" = keywords_n_Oregon, "query_Wa" = keywords_n_Washington, "total_Or"= total_n_Oregon, "total_Wa" = total_n_Washington)

#proportion test for each week
OvsW = n_tweets_week %>% 
  group_by(keywords, week) %>% 
  summarize(
    proptest = list(
      prop.test(x = c(query_Or, query_Wa), n = c(total_Or, total_Wa), alternative = "two.sided", correct = TRUE) 
      #continuity correction false because it only matters for small sample sizes. For our sizes, result is the same with and without
      )
  ) %>% 
  ungroup() 
OvsW$keywords =   dplyr::recode(OvsW$keywords, "Breaking the silence" = "Campaign")

#put important estimates into a table
OvsW$pr_diff= round(sapply(OvsW$proptest, function(x) x$estimate[1])-(sapply(OvsW$proptest, function(x) x$estimate[2])), 3)*100
OvsW$pr_Or= round(sapply(OvsW$proptest, function(x) x$estimate[1]),4)*100
OvsW$pr_Wa= round(sapply(OvsW$proptest, function(x) x$estimate[2]),4)*100
OvsW$Chisquared = round(sapply(OvsW$proptest, function(x) x$statistic), 2)
OvsW$df = sapply(OvsW$proptest, function(x) x$parameter)
OvsW$p.value = round(sapply(OvsW$proptest, function(x) x$p.value), 3)
OvsW$ci_lower = round(sapply(OvsW$proptest, function(x) x$conf.int[1]), 4)*100
OvsW$ci_upper = round(sapply(OvsW$proptest, function(x) x$conf.int[2]), 4)*100
```


### Campaign related keywords - Proportion tests

The campaign week is week 15. All weeks before with values > 0 are shown, and 9 weeks after (the entire "After" period). 

```{r}
select(OvsW, -c(proptest)) %>% 
  filter(is.na(Chisquared)==FALSE) %>%
  filter(week < 26) %>% 
  filter(keywords == "Campaign")
```

### Lifeline related keywords - Proportion tests

```{r}
select(OvsW, -c(proptest)) %>% 
  filter(is.na(Chisquared)==FALSE) %>%
  filter(keywords =="Lifeline") %>% 
  slice(1:28)
```

\newpage

# Time series around campaign week: Absolute percentages 

Lines indicate the percentage of tweets that contained at least one keyword. Shaded areas around the lines are 95% binomial confidence intervals. 
The vertical lines in the plots indicate the date of certain events that were mentioned in tweets containing our keywords. Their color indicates if the event was Lifeline-related (in green), or a suicide case (in red). The grey dashed lines always indicate the week of the _Breaking the silence_ campaign in Oregon (April 7-14th 2019). 

Vertical lines in the plot below indicate the following events:

* Green: February 19 2019: the transgender Lifeline gets introduced
* Red: March 23 and 25 2019: peak before the campaign: Two Parkland survivors, and then the father of a Sandy Hook victim die by suicide ([source](https://www.ctvnews.ca/world/two-parkland-survivors-father-of-sandy-hook-victim-die-by-suicide-1.4351198))

```{r}
df_or <- df %>% 
  filter(state=="Oregon" & date>as.Date("2019-02-01") & date < as.Date("2019-06-01") )
df_wa <- df %>% 
  filter(state=="Washington" & date>"2019-02-01"&date<"2019-06-01")
if(total=="all"){
  ts_or <- events1819(plotTS(df=df_or, mode="percent_abs", title="Oregon - absolute percentage",  limits=c(-0.01,0.13)))
   ts_wa <- events1819(plotTS(df=df_wa, mode="percent_abs", title="Oregon - absolute percentage",  limits=c(-0.01,0.13)))
} else { 
  ts_or <- events1819(plotTS(df=df_or, mode="percent_abs", title="Oregon - absolute percentage",  limits=c(-0,40)))
   ts_wa <- events1819(plotTS(df=df_wa, mode="percent_abs", title="Oregon - absolute percentage",  limits=c(-0,40)))
}

  
plot.abs <- plot_grid(ts_or, ts_wa, ncol=1)
```

Results shown in the following plot: 

* During the campaign, tweets containing the campaign terms "Break the Silence" increase from `r round(median(filter(df, state=="Oregon" & keywords=='Breaking the silence'& period=="Baseline")$pr))`% to a peak of `r round(max(filter(df_or, keywords=='Breaking the silence'&period=="Campaign-week")$pr),3)`%, or a median of `r round(median(filter(df, keywords=='Breaking the silence'&period=="Campaign-week")$pr),3)`% of all tweets in Oregon. This increase is comparable to the one after the introduction of the helpline for transgender individuals. 
* Lifeline-related tweets increased from a baseline of `r round(median(filter(df, state=="Oregon" & keywords=='Lifeline'& period=="Baseline")$pr),3)`% to a peak of `r round(max(filter(df_or, keywords=='Lifeline'&period=="Campaign-week")$pr),3)`%, or a median of `r round(median(filter(df, keywords=='Lifeline'&period=="Campaign-week")$pr),3)`%.
* In Washington, these tweets do not increase significantly. 
* Just before the campaign, and after the suicides of 3 individuals (victims and bereaved of school shootings), the percentage of tweets containing Lifeline terms (Lifeline names and numbers, "BeTheOneToo") increased to 0.1% of all tweets in both Oregon and Washington. 
* The word clouds for April 16-17th (the little peak of Lifeline tweets after the campaign week) do not reveal a special event, there were simply a lot of tweets with the Lifeline number on those days, in both Oregon and Washington. 

```{r, ts absolute campaign, fig.height=8, fig.width=6}
plot.abs
```

\newpage

# Checking the baseline period

## Time series during baseline: Absolute percentages in 2018

We will calculate the year 2018 as baseline per query and per state. Peaks in the plot below coincide with these events (suicide cases in red and suicide prevention events in green):

* January 2 2018: outrage about video by youtuber Paul Logan, that shows a dead body ([source](https://www.theatlantic.com/technology/archive/2018/01/a-social-media-stars-error/549479/))
* January 16 2018: suicide of Tyler Hilinski, American football player
* June 5 2018: suicide of Kate Spade, designer
* June 8 2018: suicide of Anthony Bourdain
* September 10 2018/2019: world suicide prevention day
* December 16 2018: 3-digit suicide hotline number gets introduced

Results of the plots below:

* The baseline is very low, apart from very few high spikes associated with suicide cases or Lifeline-related events. So that these outlier events do not influence the baseline, we take the median rather than the mean. 
* Breaking the silence tweets, i.e. tweets with the terms breaking the silence, do not seem to occur often enough to be visible in this plot. 
* The baseline is very similar in both states. 

```{r, ts entire period, fig.height=8, fig.width=7}
df_or <- df %>% 
  filter(state=="Oregon" & period=="Baseline")
ts_or <- events1819(plotTS(df=df_or, mode="percent_abs", title="Oregon - Baseline period", textsize=13, axistextsize = 12)) # limits=c(-1,49),

df_wa <- df %>% 
  filter(state=="Washington" & period=="Baseline")
ts_wa <- events1819(plotTS(df=df_wa, mode="percent_abs", title="Washington - Baseline period", textsize=13, axistextsize = 12)) # limits=c(-1,49),

plot_grid(ts_or, ts_wa, ncol=1)
```

Peaks of outlier events above n=200 Lifeline-related tweets (i.e. above 0.06%) in 2018. Numbers are  the average across Oregon and Washington, since they are so similar. This shows that these peaks are up to 200 times higher than the median number of tweets per day. On 9.6.2018 (suicide of Anthony Bourdain, a few days after Kate Spade), there were 1914 tweets, while the daily median is 10.

```{r}
as.data.frame(df %>% 
                filter(keywords_n>200 & date < '2019-01-01') %>%
                group_by(date, keywords) %>% 
                summarise(statemean_n = mean(keywords_n), 
                          steatemean_pr = mean(pr)) %>% 
                arrange(date))
```

# Time periods

We investigate the number and percentage of tweets with lifeline or breaking the silence keywords across 4 time periods: 

```{r}
df %>% 
  group_by(period) %>% 
  summarise(start = first(date), 
            end = last(date))
```



## Weekly fluctuation of Lifeline-related tweets?

Is there a weekly fluctuation of Lifeline tweets, e.g. because the Lifeline is mostly posted by professionals during their working time?

```{r, weekly fluctuation of tweets, fig.width=7, fig.height=4}
ggplot(data=filter(df, date < as.Date("2018-06-01")))+
  geom_line( aes(x=date, y=keywords_n, colour=keywords))+
  theme_bw()+theme(legend.position=c(0.87,0.82))+
  ylim(c(0,180))+labs(y="n tweets per day", x="")+
  ggtitle("N tweets per day, excluding spikes above 180, January-June 2018")+
  scale_colour_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")
```

No clear weekly pattern visible in the plot above - how do weekly averages look like?

```{r, tweets per weekday in 2018, fig.width=7, fig.height=7}
perweekday <- df %>% 
  group_by(weekday, keywords) %>% 
  filter(period=="Baseline") %>% 
  summarise(mean_n =mean(keywords_n), 
            median_n=median(keywords_n), 
            mean_pr =mean(pr), 
            median_pr=median(pr)) %>% 
  ungroup() %>% 
 pivot_longer(cols=c(mean_n, median_n, mean_pr, median_pr),
  names_to = c("Average", ".value"),
  names_sep ='_')

weekday_n <- ggplot(data=perweekday)+
  geom_point(aes(x=weekday, y=n, group=Average, colour=keywords, shape=Average), size=3)+
  geom_line(aes(x=weekday, y=n, group=paste(keywords, Average), colour=keywords, linetype=Average))+
  theme_bw()+theme(legend.position="none")+
  ylim(c(0,60))+labs(y="n tweets", x="")+
  ggtitle("Tweets with keywords per weekday")+
  scale_colour_manual(values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  scale_shape_manual(values=c(18,5))
weekday_pr <- ggplot(data=perweekday)+
  geom_point(aes(x=weekday, y=pr, group=Average, colour=keywords, shape=Average), size=3)+
  geom_line(aes(x=weekday, y=pr, group=paste(keywords, Average), colour=keywords, linetype=Average))+
  theme_bw()+theme(legend.position="top")+
  labs(y="% tweets", x="")+
  scale_colour_manual(values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  scale_shape_manual(values=c(18,5))
plot_grid(weekday_n, weekday_pr, nrow=2)
```

* The median, which is not influenced by outlier events, is flat, indicating that there is no regular fluctuation of tweets with the Lifeline number or name, or betheonetoo terms. 
* The mean shows that the outlier events have an effect on the baseline, although it is minimal. We will therefore use the median across all days in 2018, irrespective of weekday, as a baseline. 
* Breaking the silence tweets have a median of `r filter(perweekday, Average=="median" & keywords=='Breaking the silence')$n[1]` (`r filter(perweekday, Average=="median" & keywords=='Breaking the silence')$pr[1]`%), while Lifeline tweets vary around `r median(round(filter(perweekday, Average=="median" & keywords=='Lifeline')$n,0))` `r median(round(filter(perweekday, Average=="median" & keywords=='Lifeline')$pr,3))`per day. 



# Time series around campaign week: Difference to the baseline

Baseline: Median level per state and keyword 2018. Peaks coincide with these events (suicide cases in red and suicide prevention events in green):

* February 19 2019: transgender Lifeline gets introduced
* March 23 and 25 2019: peak before the campaign: Two Parkland survivors, and then the father of a Sandy Hook victim die by suicide ([source](https://www.ctvnews.ca/world/two-parkland-survivors-father-of-sandy-hook-victim-die-by-suicide-1.4351198))

Results in the following plot: 

* The change in percentage of tweets with keywords compared to baseline is much larger when we look at tweets that contain both the campaign words and suicid*. This is probably because tweets referring to the campaign are very rare usually. 
* The change is very clear in Oregon, and entirely absent in Washington.
* Because the baseline is nearly zero in both states, the difference to the baseline looks very similar to absolute (uncorrected) levels. 

```{r, ts change campaign, fig.height=8, fig.width=12}
df_or <- df %>% 
  filter(state=="Oregon" & date>as.Date("2019-02-01") & date < as.Date("2019-06-01") )
df_wa <- df %>% 
  filter(state=="Washington" & date>"2019-02-01"&date<"2019-06-01")
if(total=="all"){
 ts_or <- events1819(plotTS(df=df_or, mode="percent_change", title="Oregon minus baseline", legpos="none",  limits=c(-0.01,0.13)))
   ts_wa <- events1819(plotTS(df=df_wa, mode="percent_change", title="Washington minus baseline",  limits=c(-0.01,0.13)))
} else { 
  ts_or <- events1819(plotTS(df=df_or, mode="percent_change", title="Oregon minus baseline", legpos="none", limits=c(-5,40)))
  ts_wa <- events1819(plotTS(df=df_wa, mode="percent_change", title="Washington minus baseline",   limits=c(-5,40)))
}

#add absolute and change plot together
plot.change <- plot_grid(ts_or, ts_wa, ncol=1)
plot_grid(plot.abs, plot.change)
```


\newpage


# Time series after the campaign: Difference to the baseline

* Red line on June 25th: lots of Lifeline tweets are posted in response to the news about Etika's suicide around June 20th ([source](https://en.wikipedia.org/wiki/Etika#Disappearance_and_death))
* Green line on September 10th: world suicide prevention day
* Green line on October 10th: world mental health day focus on suicide prevention ([source](https://www.who.int/news-room/events/detail/2019/10/10/default-calendar/world-mental-health-day-2019-focus-on-suicide-prevention))

The peaks associated with these outlier events with more than 200 Lifeline-related tweets are (Numbers are  the average across Oregon and Washington, since they are so similar.):

```{r}
as.data.frame(df %>% 
                filter(keywords_n>200 & date > '2019-01-01') %>%
                group_by(date, keywords) %>% 
                summarise(statemean_n = mean(keywords_n), 
                          statemean_pr = mean(pr)) %>% 
                arrange(date))
```


The plot below shows that the campaign messages were pushed again slightly around world suicide prevention day, given that people tweeted about it again. 


```{r, ts after campaign, fig.height=15, fig.width=14}
df_or <- df %>%
  filter(state=="Oregon" & date>"2019-04-01")
df_wa <- df %>%
  filter(state=="Washington"& date>"2019-04-01")

if(total=="all"){
  ts_or <- events1819(plotTS(df=df_or, title="Oregon - After campaign", limits=c(-0.01,0.13), textsize=25, axistextsize = 16, legpos=c(0.5,0.8)))
  ts_wa <- events1819(plotTS(df=df_wa, title="Washington - After campaign", limits=c(-0.01,0.13), textsize=25, axistextsize = 16, legpos=c(0.5,0.8)))
} else { 
  ts_or <- events1819(plotTS(df=df_or, title="Oregon - After campaign", limits=c(-5,40), textsize=25, axistextsize = 16, legpos=c(0.5,0.8)))
  ts_wa <- events1819(plotTS(df=df_wa, title="Washington - After campaign", limits=c(-5,40), textsize=25, axistextsize = 16, legpos=c(0.5,0.8)))
}

plot_grid(ts_or, ts_wa, ncol=1)
```

\newpage

# Difference Oregon - Washington 

* The dots in the plot indicate levels of tweets with campaign or Lifeline terms in Oregon. By comparing this with the lines that show the difference to Washington, we can see that the difference during the campaign week is explained by an increase of terms in Oregon, as there was no change in Washington. 

```{r, d}
  diff_blcorrected <- df %>% 
  group_by(keywords, date) %>%
  mutate(pr_diff=(pr[state=="Oregon"]-bl[state=="Oregon"])-(pr[state=="Washington"]-bl[state=="Washington"]),
         prlow1 =(prlow[state=="Oregon"]-bl[state=="Oregon"])-(prlow[state=="Washington"]-bl[state=="Washington"]),
         prhigh1 =(prhigh[state=="Oregon"]-bl[state=="Oregon"])-(prhigh[state=="Washington"]-bl[state=="Washington"])) %>% 
  filter(state=="Oregon") %>% #select Oregon lines only, because the difference is the same for both states
  select(date, keywords, pr_diff, prlow1, prhigh1) %>% 
  rename(pr=pr_diff, prlow=prlow1, prhigh=prhigh1) %>% 
  arrange(date) %>% 
  ungroup() 
# mutate(keywords = recode(keywords, Lifeline = 'Difference Lifeline', Breaking the silence = 'Difference campaign'))
#calculate proportional change - decide how to do this because of baseline=0 for some keywords
# mutate(pr_ovsw = case_when(
#   any(pr==0)==FALSE ~ (pr[state=="Oregon"]-pr[state=="Washington"])/pr[state=="Washington"],
#   TRUE ~ 0) ) %>% 
# select(date, keywords, state, pr, pr_ovsw, prlow, prhigh)

# make the plot
textsize=13
axistextsize=12
if(total=="all"){
  ylims = c(-0.01,0.13)
  pos_extralegend = 0.075 #position of manually added legend ... Oregon
} else { 
  ylims = c(-12,40)
  pos_extralegend = 15.7
}
plot.statediff <-ggplot(filter(diff_blcorrected,  date>"2019-02-07"&date<"2019-06-14") )+ 
  # plot the difference
  geom_ribbon(aes(x=date, ymin=prlow, ymax=prhigh, fill=keywords, colour=keywords), alpha=0.3, size=0) +
  geom_line( aes(x=date, y=pr, colour=keywords))+
  ylab("Difference % tweets (O-W)") +
  # scale_y_continuous(limits = ylims)+
  ggtitle("Difference between Oregon and Washington")+
  scale_fill_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  scale_colour_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  theme_bw()+ theme(text=element_text(size=textsize), axis.text=element_text(size=axistextsize),
                    axis.title.x = element_blank(),
                    axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1),
                    legend.position=c(0.8,0.75),
                    plot.margin = margin(0.5,0.5,0.5,0.5, "cm"),
                    panel.grid.minor= element_blank())+
  scale_x_date(date_breaks="1 month", date_labels = "%b")+
  geom_hline(yintercept = 0, colour = "grey50")+ #mean line
  geom_vline(xintercept = as.Date("2019-04-05"), colour = "grey50", linetype=2)+ #campaign week start
  geom_vline(xintercept = as.Date("2019-04-14"), colour = "grey50", linetype=2) #campaign week end

#add event lines and the levels minus baseline in Oregon for comparison reasons
events1819(plot.statediff+
             #plot the level in Oregon, it should be similar to the difference during the campaign week, given that the level is almost 0 in Washington
             geom_line(data = filter(df, state=='Oregon' & date>"2019-03-01"&date<"2019-06-01"), aes(x=date, y=pr-bl, colour=keywords), linetype=3, size=0.7)+
             annotate(geom="text", x=as.Date("2019-05-21"), y=pos_extralegend, label="....   Levels in Oregon", size=3.65))
```

* The increase of tweets containing the Breaking the silence terms (Lifeline) and of Lifeline terms (life line name and numbers and BeTheOneToo) was higher in Oregon than in Washington.
* The pattern of differences during the campaign week looks almost exactly like the levels in Oregon itself, indicating  that the difference was entirely driven by Oregon (which makes sense as there was almost no social media response in Washington). 
* Outside of the campaign week, tweets with Lifeline terms change similarly in both states, as indicated by very small differences. Only the spike in response to 3 suicides after March 23rd was slightly larger in Oregon than Washington (0.03%).

\newpage

# Plot for paper: Both states and their difference

All timelines in the figure below are baseline corrected. The figure shows the time series of Breaking the silence and Lifeline tweets 2 months before and 2 months after the campaign week, specifically from February 7th to June 14th 2019. 

```{r, summary figure states and difference, fig.height=8, fig.width=12}
df_or <- df %>%
  filter(state=="Oregon" & date>"2019-02-07"&date<"2019-06-14")
if(total=="all"){
  ts_or <- events1819(plotTS(df=df_or, title="Oregon",  limits=c(-0.01,0.13)))
} else { 
  ts_or <- events1819(plotTS(df=df_or, title="Oregon", limits=c(-5,40), legpos="none"))
}

#Washington
df_wa <- df %>%
  filter(state=="Washington" & date>"2019-02-07"&date<"2019-06-14")
if(total=="all"){
  ts_wa <- events1819(plotTS(df=df_wa, title="Washington",  limits=c(-0.01,0.13), legpos="none"))
} else { 
  ts_wa <- events1819(plotTS(df=df_wa, title="Washington",   limits=c(-5,40), legpos="none"))
}

#difference plot
ts_diff <- events1819(plot.statediff+
                        #remove the legend
                        theme(legend.position="right", 
                              axis.text.x=element_text(angle=0, vjust=0.5, hjust=0.5)))

   # pdf('figures/oregon_washington_absolute&difference_aroundcampaignweek.pdf', height=7, width=11)
  plot_grid(plot_grid(ts_or, ts_wa, labels=c("A", "B")),
            plot_grid(ts_diff, rel_widths=c(1.88,1), ncol=2, labels="C"),
            nrow=2)
   # dev.off()
```


\newpage

# Do Breaking the silence tweets occur at all during the baseline?

Limit the y-scale to check if small percentages below 5% occur: 

```{r, campaign tweets below 5 before campaign, fig.height=6, fig.width=7}
if(total=="all"){
 ylims =c(0, 0.045)
} else { 
 ylims =c(0,5)
}
fontsingleplots = 11
ggplot(data=filter(df, keywords=="Breaking the silence"))+
  geom_line( aes(x=date, y=pr, colour=keywords))+
  facet_grid(rows=vars(state))+
  ylab("% tweets with keywords") +
  ggtitle("Breaking the silence tweets below 5% during entire period")+ #plot title
  scale_fill_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  scale_colour_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+ 
  theme_bw()+ theme(text=element_text(size=fontsingleplots), axis.text=element_text(size=fontsingleplots), 
                    axis.title.x = element_blank(),
                    axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1), 
                    legend.position='none',
                    plot.margin = margin(0.5, 0.5, 2, 0.5, "cm"), 
                    panel.grid.minor= element_blank())+
  scale_x_date(date_breaks="1 month", date_labels = "%b")+
  geom_hline(yintercept = 0, colour = "grey50")+ #mean line
  geom_vline(xintercept = as.Date("2019-04-05"), colour = "grey50", linetype=2)+ #campaign week start
  geom_vline(xintercept = as.Date("2019-04-14"), colour = "grey50", linetype=2)+ #campaign week end
  ylim(ylims)
```

\newpage

To look at the small frequencies before and after the campaign, I cut the y-scale to 0.002 percent max (1.0 would be 1%). Because of this, the high frequencies during the campaign week are not displayed, and the campaign week window is empty. This shows that Lifeline terms were used on 3 or 4 days (depending on the state) before the campaign, but at a negligible percentage below 0.0005%. 

```{r, campaign tweets below 2 before campaign, fig.height=6, fig.width=7}
if(total=="all"){
 ymax =c(0.002)
} else { 
 ymax =c(2)
}
ggplot(data=filter(df, keywords=="Breaking the silence"))+
  geom_line( aes(x=date, y=pr, colour=keywords))+
  facet_grid(rows=vars(state))+
  ylab("% tweets with keywords") +
  ggtitle(paste0("Breaking the silence tweets below ", ymax, "% during entire period"))+ #plot title
  scale_fill_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  scale_colour_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+ 
  theme_bw()+ theme(text=element_text(size=fontsingleplots), axis.text=element_text(size=fontsingleplots), 
                    axis.title.x = element_blank(),
                    axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1), 
                    legend.position="none",
                    plot.margin = margin(0.5, 0.5, 2, 0.5, "cm"), 
                    panel.grid.minor= element_blank())+
  scale_x_date(date_breaks="2 month", date_labels = "%b")+
  geom_hline(yintercept = 0, colour = "grey50")+ #mean line
  geom_vline(xintercept = as.Date("2019-04-05"), colour = "grey50", linetype=2)+ #campaign week start
  geom_vline(xintercept = as.Date("2019-04-14"), colour = "grey50", linetype=2)+ #campaign week end
  ylim(0,ymax)
```

What number of tweets do these percentages represent? Only 1 tweet for each occurence during the baseline period. 
  
```{r, n campaign tweets before campaign, fig.height=6, fig.width=7}

ggplot(data=filter(df, keywords=="Breaking the silence"))+
  geom_line( aes(x=date, y=keywords_n, colour=keywords))+
  facet_grid(rows=vars(state))+
  ylab("% tweets with keywords") +
  ggtitle("Breaking the silence tweets number during entire period")+ #plot title
  scale_fill_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+
  scale_colour_manual(  values = c("Breaking the silence"="blue", "Lifeline"="cyan"), name="Keywords in tweets")+ 
  theme_bw()+ theme(text=element_text(size=fontsingleplots), axis.text=element_text(size=fontsingleplots), 
                    axis.title.x = element_blank(),
                    axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1), 
                    legend.position="none",
                    plot.margin = margin(0.5, 0.5, 2, 0.5, "cm"), 
                    panel.grid.minor= element_blank())+
  scale_x_date(date_breaks="2 month", date_labels = "%b")+
  geom_hline(yintercept = 0, colour = "grey50")+ #mean line
  geom_vline(xintercept = as.Date("2019-04-05"), colour = "grey50", linetype=2)+ #campaign week start
  geom_vline(xintercept = as.Date("2019-04-14"), colour = "grey50", linetype=2)+ #campaign week end
  ylim(0,5)
```



\newpage

# Entire time period time series

```{r, fig.height=7}
events1819(plotTS(df=df, mode="number", title="Daily tweets cut at max 300 - Entire timeperiod", limits=c(0,300), textsize=13, axistextsize = 10, legpos="bottom"))+facet_grid(rows="state")+xlim(as.Date("2018-01-01"), as.Date("2019-11-30"))
```

